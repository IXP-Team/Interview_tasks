{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Image-processing\" data-toc-modified-id=\"Image-processing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Image processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Task-1:\" data-toc-modified-id=\"Task-1:-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Task 1:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reading-data\" data-toc-modified-id=\"Reading-data-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Reading data</a></span></li><li><span><a href=\"#Visualizing-the-location-of-cursor\" data-toc-modified-id=\"Visualizing-the-location-of-cursor-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Visualizing the location of cursor</a></span></li><li><span><a href=\"#Exporting-a-video-file\" data-toc-modified-id=\"Exporting-a-video-file-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Exporting a video file</a></span></li><li><span><a href=\"#Average-location-of-cursor\" data-toc-modified-id=\"Average-location-of-cursor-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Average location of cursor</a></span></li><li><span><a href=\"#Visualizing-the-heatmap\" data-toc-modified-id=\"Visualizing-the-heatmap-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>Visualizing the heatmap</a></span></li></ul></li><li><span><a href=\"#Task-2\" data-toc-modified-id=\"Task-2-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Task 2</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: \n",
    "### Reading data\n",
    "you are given a text file `mousePos.txt` which contain the `(x,y)` position of a mouse cursor. Extract the data of the cursor positions in an automated manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: import the required libraries\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import csv\n",
    "#import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to parse the x and y corrdinates of the mouse cursor from the given text file\n",
    "\n",
    "def splitter(txt):\n",
    "    # this fucntion takes one line of the text as input and provide us the informatiion that we require for our later use.\n",
    "    # input argument: txt: one line from the text file\n",
    "    # ouput arguments: vx: x coorrdinate of the mouse \n",
    "    #                  vy: y coordinate of the mouse\n",
    "    \n",
    "    \n",
    "    arr1 = txt.split(\",\") # spit by commas and give an array\n",
    "    txt2 = arr1[2]        # indix of our interst \n",
    "    arr2 = txt2.split(\" \") # further spilt by space\n",
    "    x = arr2[2]          #  to get x coordinate\n",
    "    y = arr2[3]          # to get y cordinates\n",
    "\n",
    "    vx = x.split(\":\")[1] # value of the x coordinate\n",
    "    vy = y.split(\":\")[1] # value of the y coordinate\n",
    "\n",
    "    return [vx, vy]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# enter the file name with the path of the text file \n",
    "file_name = 'C:/Users/muhammad.saif/Desktop/MyCloud/ixp_interview_tasks/Interview_tasks-main/ImageTask/mousePos.txt'\n",
    "num_lines = sum(1 for line in open(file_name)) # total number of lines\n",
    "xy = np.zeros((num_lines,2))  # preallocation to save the results\n",
    "line_ind = 0 # starting index of the line\n",
    "\n",
    "#extracting the x and y coordinates of the mouse at each timestamp\n",
    "with open(file_name) as f:\n",
    "    for line in f.readlines():\n",
    "        x_corr,y_corr=splitter(line) #calling the above defined function\n",
    "        xy_new = np.array([int(x_corr),int(y_corr)]) # converting it to as np array\n",
    "        xy_new = np.expand_dims(xy_new,axis=0) # expanding the dimension\n",
    "        xy[line_ind,:] = xy_new # saving the results to xy\n",
    "        line_ind += 1 # incrementing the line indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the location of cursor \n",
    "‚ùì Visualize the current and the last 20 positions of the cursor with the image `Desktop.png` as a background image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Desktop.png](./Desktop.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1821\n",
      "[[647  64]\n",
      " [651  72]\n",
      " [651  72]\n",
      " [656  80]\n",
      " [656  80]\n",
      " [661  89]\n",
      " [661  89]\n",
      " [666  99]\n",
      " [666  99]\n",
      " [671 108]\n",
      " [671 108]\n",
      " [676 119]\n",
      " [681 131]\n",
      " [681 131]\n",
      " [687 145]\n",
      " [687 145]\n",
      " [695 156]\n",
      " [703 169]\n",
      " [703 169]\n",
      " [711 180]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 20 is out of bounds for axis 0 with size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-900f02ee100d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mcursor_position\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mlast_20_positions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_resize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor_position\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthickness\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 20 is out of bounds for axis 0 with size 20"
     ]
    }
   ],
   "source": [
    "\n",
    "# In this cell, I selected the the start point of the cursor randomaly and then plotted the last 20 position of the cursors using\n",
    "# the extracted corrdinates from the text file (see above cell). \n",
    "#enter the complete path of  'Desktop.png'\n",
    "\n",
    "# desktop image path: please provide it accordingly.\n",
    "desktop_img_path = 'C:/Users/muhammad.saif/Desktop/MyCloud/ixp_interview_tasks/Interview_tasks-main/ImageTask/Desktop.png'\n",
    "\n",
    "img = cv2.imread(desktop_img_path)  # reading image using open cv\n",
    "current_height,current_width,depth = img.shape # image height, image width and depth (number of channels)\n",
    " \n",
    "#resizing the image to fit on a small secreen (original was not fitting on my laptop screen) \n",
    "# the aspect ratio of original image to resized image is kept the same.\n",
    "new_height = 256\n",
    "new_width  = 896\n",
    "img_resize = cv2.resize(img,(new_width,new_height))\n",
    "img_for_visualization = cv2.resize(img,(new_width,new_height))\n",
    "size = new_width,new_height\n",
    "\n",
    "cv2.imshow(\"Image\", img_resize)\n",
    "cv2.waitKey()\n",
    "\n",
    "# mapping of the given x_coordinates and y_coordinates to the  resized images \n",
    "x_transformed = ((xy[:,0]/current_width)*new_width).astype(int) # mapping of the x coordinate\n",
    "y_transformed = ((xy[:,1]/current_height)*new_height).astype(int) # mapping of the y coordinate\n",
    "\n",
    "x_transformed = np.expand_dims(x_transformed,axis=-1)\n",
    "y_transformed = np.expand_dims(y_transformed,axis=-1)\n",
    "xy_transformed = np.concatenate((x_transformed,y_transformed),axis=1) \n",
    "\n",
    "### gennerating the current cursor position randomly \n",
    "current_cursor_ind = np.random.randint(21, num_lines, size=1)[0] # generated the current cursor position randomly\n",
    "print(current_cursor_ind)\n",
    "\n",
    "last_20_positions = xy_transformed[current_cursor_ind-20:current_cursor_ind,:] # fectching the last 19 positions of the cursor\n",
    "print(last_20_positions)\n",
    "\n",
    "##--------------------------------------------------------------------------------------------------------------\n",
    "##------------------------Important information------------------------------------------------------------------\n",
    "##--------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# it possible that cursor do not move in all selec poistions, so, i would recommend to run this cell multiple times so that \n",
    "# one see that cursor postion is channging.\n",
    " #----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    \n",
    "img_array = np.zeros([21,new_height,new_width,3]).astype('uint8') ## preallocation to save the all the images \n",
    "#base_path = 'C:/Users/muhammad.saif/Desktop/MyCloud/ixp_interview_tasks/Interview_tasks-main/ImageTask/'\n",
    "\n",
    "##---------------------------------------------------------------------------------------------------\n",
    "##----------------------- now to show the cursors on the desktop image-------------------------------\n",
    "##---------------------------------------------------------------------------------------------------\n",
    "\n",
    "for i in range(21):\n",
    "    cursor_position =  last_20_positions[i]\n",
    "    image = cv2.circle(img_resize, cursor_position, radius=1, color=(0, 0, 255), thickness=-1)\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    key = cv2.waitKey()\n",
    "    img_array[i,:,:,:] = image # saving each imagae to the prallocted space\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting a video file\n",
    "‚ùì Export the results of the previous task into a vidoe file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, the images that are saved in 'img_array' are used to create a video. This video will automatically be saved to \n",
    "# the base_path with name 'cursor_positions.avi'\n",
    "base_path = 'C:/Users/muhammad.saif/Desktop/Interview_tasks-main/ImageTask/'\n",
    "video_file_path = base_path + 'cursor_positions.avi' # change the base path to your desired location to save the video file\n",
    "out = cv2.VideoWriter(video_file_path,cv2.VideoWriter_fourcc(*'DIVX'), 5, size) \n",
    "for i in range(len(img_array)):\n",
    "    img = img_array[i]\n",
    "    out.write(img)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average location of cursor\n",
    "‚ùì Calcualte the average positon of the cursor, and save the content into csv file with proper header. \n",
    "\n",
    "***repeate the process 10 times and visualize the average cursor position***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   repetition  average x  average y\n",
      "0           0        445         49\n",
      "1           1        301        120\n",
      "2           2        578         87\n",
      "3           3        407        146\n",
      "4           4        574         87\n",
      "5           5        312         46\n",
      "6           6        867        248\n",
      "7           7        173        207\n",
      "8           8        578         87\n",
      "9           9        188         22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In this cell, i randomly generted the 10 current positions of cursors and then calculted the mean of the last 20 positions\n",
    "# each time\n",
    "\n",
    "# Secondly:  i created the csv (comma seperated value) file with a header 'repetition', 'average x', 'average y', and save\n",
    "# the results in it\n",
    "\n",
    "\n",
    "# Thirdly: visualization of the average curos positions\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "##-------part 1: randomly geneerted the  current position---------------------------\n",
    "##---------------------------------------------------------------------------------\n",
    "num_reps = 10 # total 10 times\n",
    "cursor_starting_ind_10 = np.random.randint(21, num_lines, size=num_reps) # generating random current cursor position for 10 repetitions\n",
    "#-----------------------------------------------------------------------------------------\n",
    "##-----------part 2: calculating means for each current position and writting csv file -------------------------------------------\n",
    "##-----------------------------------------------------------------------------------\n",
    "csv_header = ['repetition', 'average x', 'average y'] # headers for csv file\n",
    "csv_data = [] \n",
    "average = []\n",
    "\n",
    "for ind,current_cursor_ind in enumerate(cursor_starting_ind_10):\n",
    "    last_20_positions = xy_transformed[current_cursor_ind-20:current_cursor_ind + 1,:] # reading current and last 20 cursor postions\n",
    "    avg = np.mean(last_20_positions,axis=0).astype(int)    \n",
    "    data = [ind, avg[0], avg[1]] \n",
    "    csv_data.append(data)\n",
    "    average.append(avg)\n",
    "    \n",
    "with open('average_cursor_postions.csv', 'w', newline='') as outcsv:\n",
    "    writer = csv.writer(outcsv)\n",
    "    writer.writerow(csv_header)  \n",
    "    writer.writerows(csv_data)\n",
    "    \n",
    "    \n",
    "####### \n",
    "#import pandas as pd\n",
    "#df = pd.read_csv('average_cursor_postions.csv')\n",
    "#print (df)\n",
    "    \n",
    " ##-------------------------------------------------------------------------------------------------------------------------   \n",
    "## part 3:  visualize average cursor positions------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#print('in visulaization part now')\n",
    "img_plotting = cv2.imread(desktop_img_path) \n",
    "img_resize_plotting = cv2.resize(img_plotting,(new_width,new_height)) \n",
    "cv2.imshow(\"Image\", image)\n",
    "key = cv2.waitKey()\n",
    "for i in range(num_reps):\n",
    "     cursor_position =  average[i]\n",
    "     image = cv2.circle(img_resize_plotting, cursor_position, radius=1, color=(0, 0, 255), thickness=-1)\n",
    "    \n",
    "     cv2.imshow(\"Image\", image)\n",
    "     key = cv2.waitKey()  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the heatmap\n",
    "‚ùì Calculate and visualize a Heatmap, stating the amount of time spent in each location. \n",
    "\n",
    "üí°  \n",
    "As an example you can look at 'Heatmap_example.jpg'.\n",
    "    ![](./Heatmap_example.jpg)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the heatmap\n",
    "unique_coords = np.unique(xy_transformed, axis=0)\n",
    "a = np.array([[1, 0, 0], [1, 0, 0], [2, 3, 4]])\n",
    "values, counts = np.unique(xy_transformed, return_counts=True,axis=0)\n",
    "heat_image = np.zeros((256,896)).astype('uint8')\n",
    "for ind, pixels in enumerate(values):  \n",
    "    x = pixels[0] #column\n",
    "    y = pixels[1] #row  \n",
    "    heat_image[y,x] = counts[ind].astype('uint8')\n",
    "# print(heat_image[25,185])\n",
    "\n",
    "sns.set_theme()\n",
    "ax = sns.heatmap(heat_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a box `(side length 20cm)` around the position of the head in `face.jpg`  \n",
    "![face.png](./face.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera parameters are `cx=250, cy=375, fx=fy=716`.  \n",
    "Head position is (in mm relative to camera) `(212, -168, 712)` with rotation (Rodrigues) `(.35, .59, -.30)`.  \n",
    "For more information look the documention of [openCV](https://docs.opencv.org/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html).  \n",
    "\n",
    "Save the overlayed image. The result should look like `face_example.jpg`, \n",
    "**make sure to choose thinner lines**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![face_example.jpg](./face_example.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###-------------Since i have ony limited knoweldge of 3-d computer vision, so the projection from 3-dimensional space to 2-dimensional\n",
    "# space was difficult for me, actually, i could not manage to to do it as asked.  but the way i did it for one of projects, by drawing mesh \n",
    "# aroun the face is given below. \n",
    "\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# For static images:\n",
    "IMAGE_FILES = ['face.jpg']\n",
    "\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5) as face_mesh:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    image = cv2.imread(file)\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print and draw face mesh landmarks on the image.\n",
    "    if not results.multi_face_landmarks:\n",
    "      continue\n",
    "    annotated_image = image.copy()\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "      #print('face_landmarks:', face_landmarks)\n",
    "      # drawing face mesh landmarks\n",
    "      mp_drawing.draw_landmarks(\n",
    "           image=annotated_image,\n",
    "           landmark_list=face_landmarks,\n",
    "           connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "           landmark_drawing_spec=None,\n",
    "           connection_drawing_spec=mp_drawing_styles\n",
    "           .get_default_face_mesh_tesselation_style())\n",
    "      \n",
    "      # plotting face mesh contours\n",
    "      mp_drawing.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "      \n",
    "      # plotting irises\n",
    "      mp_drawing.draw_landmarks(\n",
    "           image=annotated_image,\n",
    "           landmark_list=face_landmarks,\n",
    "           connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "           landmark_drawing_spec=None,\n",
    "           connection_drawing_spec=mp_drawing_styles\n",
    "           .get_default_face_mesh_iris_connections_style())\n",
    "    \n",
    "    # saving the annotated face image with landmarks\n",
    "    cv2.imwrite('annotated_face_image' + str(idx) + '.png', annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
